{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN（卷积神经网络）来实现图像识别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2 \n",
    "import math\n",
    "import dlib\n",
    "import datetime\n",
    "import random \n",
    "\n",
    "from scipy.linalg import svd\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical#Keras神经网络框架,与pytorch相似\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorboard as tb \n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(\"E:/face_dectection/figure/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:/face_dectection/figure\\\\person4\\\\page0_the_19_liuyifei.jpg',\n",
       " 'E:/face_dectection/figure\\\\person0\\\\page1_the_41_zhaoliyin.jpg',\n",
       " 'E:/face_dectection/figure\\\\person1\\\\person1page1_the_3_yangmi.jpg',\n",
       " 'E:/face_dectection/figure\\\\person1\\\\person1page1_the_19_yangmi.jpg',\n",
       " 'E:/face_dectection/figure\\\\person0\\\\page0_the_15_zhaoliyin.jpg',\n",
       " 'E:/face_dectection/figure\\\\person1\\\\person1page1_the_44_yangmi.jpg',\n",
       " 'E:/face_dectection/figure\\\\person3\\\\page1_the_34_dilireba.jpg',\n",
       " 'E:/face_dectection/figure\\\\person4\\\\page2_the_59_liuyifei.jpg',\n",
       " 'E:/face_dectection/figure\\\\person4\\\\page1_the_6_liuyifei.jpg',\n",
       " 'E:/face_dectection/figure\\\\person2\\\\page1_the_46_liyitong.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.shuffle(path)\n",
    "path[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895\n"
     ]
    }
   ],
   "source": [
    "images=[]\n",
    "count=0\n",
    "for img in path:\n",
    "    if \"jpg\" in img:\n",
    "        try:\n",
    "            n = cv2.imread(img)#发送读取错误时跳过\n",
    "            gray = cv2.cvtColor(n,cv2.COLOR_BGR2GRAY)\n",
    "        except:\n",
    "            images.append(np.zeros((50,50)))#填充错误值\n",
    "            count+=1\n",
    "            continue\n",
    "        gray = cv2.resize(gray,(50,50))\n",
    "        images.append(gray)\n",
    "        count=count+1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images= np.array(images)\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立标准\n",
    "Y_map_num = np.zeros((len(images)))\n",
    "i = 0\n",
    "for img in path:\n",
    "    if \"jpg\" in img:\n",
    "        if \"liuyifei\" in img:\n",
    "            Y_map_num[i]=0\n",
    "        elif \"yangmi\" in img:\n",
    "            Y_map_num[i]=1\n",
    "        elif \"dilireba\" in img:\n",
    "            Y_map_num[i]=2\n",
    "        elif \"liyitong\" in img:\n",
    "            Y_map_num[i]=3\n",
    "        elif \"zhaoliyin\" in img:\n",
    "            Y_map_num[i]=4\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 4., 1., 1., 4., 1., 2., 0., 0., 3., 4., 0., 2., 2., 0., 3., 0.,\n",
       "       3., 3., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Y_map_num))\n",
    "Y_map_num[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_map_label = [0 for x in range(len(images))]\n",
    "i = 0\n",
    "for img in path:\n",
    "    if \"jpg\" in img:\n",
    "        if \"liuyifei\" in img:\n",
    "            Y_map_label[i]=\"liuyifei\"\n",
    "        elif \"yangmi\" in img:\n",
    "            Y_map_label[i]=\"yangmi\"\n",
    "        elif \"dilireba\" in img :\n",
    "            Y_map_label[i]=\"dilireba\"\n",
    "        elif \"liyitong\" in img:\n",
    "            Y_map_label[i]=\"liyitong\"\n",
    "        elif \"zhaoliyin\" in img:\n",
    "            Y_map_label[i]=\"zhaoliyin\"\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['liuyifei',\n",
       " 'zhaoliyin',\n",
       " 'yangmi',\n",
       " 'yangmi',\n",
       " 'zhaoliyin',\n",
       " 'yangmi',\n",
       " 'dilireba',\n",
       " 'liuyifei',\n",
       " 'liuyifei',\n",
       " 'liyitong',\n",
       " 'zhaoliyin',\n",
       " 'liuyifei',\n",
       " 'dilireba',\n",
       " 'dilireba',\n",
       " 'liuyifei',\n",
       " 'liyitong',\n",
       " 'liuyifei',\n",
       " 'liyitong',\n",
       " 'liyitong',\n",
       " 'yangmi']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(Y_map_label))\n",
    "Y_map_label[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_categorical：to_categorical就是将类别向量转换为二进制（只有0和1）的矩阵类型表示。\n",
    "其表现为将原有的类别向量转换为独热编码的形式。\n",
    "onehot编码：https://blog.csdn.net/moyu123456789/article/details/83444140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_one_hot = to_categorical(Y_map_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 5)\n",
      "(895,)\n"
     ]
    }
   ],
   "source": [
    "# print(Y_one_hot)\n",
    "# print(Y_map_num)\n",
    "print(Y_one_hot.shape)\n",
    "print(Y_map_num.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reshape in module numpy:\n",
      "\n",
      "reshape(a, newshape, order='C')\n",
      "    Gives a new shape to an array without changing its data.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Array to be reshaped.\n",
      "    newshape : int or tuple of ints\n",
      "        The new shape should be compatible with the original shape. If\n",
      "        an integer, then the result will be a 1-D array of that length.\n",
      "        One shape dimension can be -1. In this case, the value is\n",
      "        inferred from the length of the array and remaining dimensions.\n",
      "    order : {'C', 'F', 'A'}, optional\n",
      "        Read the elements of `a` using this index order, and place the\n",
      "        elements into the reshaped array using this index order.  'C'\n",
      "        means to read / write the elements using C-like index order,\n",
      "        with the last axis index changing fastest, back to the first\n",
      "        axis index changing slowest. 'F' means to read / write the\n",
      "        elements using Fortran-like index order, with the first index\n",
      "        changing fastest, and the last index changing slowest. Note that\n",
      "        the 'C' and 'F' options take no account of the memory layout of\n",
      "        the underlying array, and only refer to the order of indexing.\n",
      "        'A' means to read / write the elements in Fortran-like index\n",
      "        order if `a` is Fortran *contiguous* in memory, C-like order\n",
      "        otherwise.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    reshaped_array : ndarray\n",
      "        This will be a new view object if possible; otherwise, it will\n",
      "        be a copy.  Note there is no guarantee of the *memory layout* (C- or\n",
      "        Fortran- contiguous) of the returned array.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.reshape : Equivalent method.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    It is not always possible to change the shape of an array without\n",
      "    copying the data. If you want an error to be raised when the data is copied,\n",
      "    you should assign the new shape to the shape attribute of the array::\n",
      "    \n",
      "     >>> a = np.zeros((10, 2))\n",
      "    \n",
      "     # A transpose makes the array non-contiguous\n",
      "     >>> b = a.T\n",
      "    \n",
      "     # Taking a view makes it possible to modify the shape without modifying\n",
      "     # the initial object.\n",
      "     >>> c = b.view()\n",
      "     >>> c.shape = (20)\n",
      "     Traceback (most recent call last):\n",
      "        ...\n",
      "     AttributeError: Incompatible shape for in-place modification. Use\n",
      "     `.reshape()` to make a copy with the desired shape.\n",
      "    \n",
      "    The `order` keyword gives the index ordering both for *fetching* the values\n",
      "    from `a`, and then *placing* the values into the output array.\n",
      "    For example, let's say you have an array:\n",
      "    \n",
      "    >>> a = np.arange(6).reshape((3, 2))\n",
      "    >>> a\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5]])\n",
      "    \n",
      "    You can think of reshaping as first raveling the array (using the given\n",
      "    index order), then inserting the elements from the raveled array into the\n",
      "    new array using the same kind of index ordering as was used for the\n",
      "    raveling.\n",
      "    \n",
      "    >>> np.reshape(a, (2, 3)) # C-like index ordering\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(np.ravel(a), (2, 3)) # equivalent to C ravel then C reshape\n",
      "    array([[0, 1, 2],\n",
      "           [3, 4, 5]])\n",
      "    >>> np.reshape(a, (2, 3), order='F') # Fortran-like index ordering\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    >>> np.reshape(np.ravel(a, order='F'), (2, 3), order='F')\n",
      "    array([[0, 4, 3],\n",
      "           [2, 1, 5]])\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([[1,2,3], [4,5,6]])\n",
      "    >>> np.reshape(a, 6)\n",
      "    array([1, 2, 3, 4, 5, 6])\n",
      "    >>> np.reshape(a, 6, order='F')\n",
      "    array([1, 4, 2, 5, 3, 6])\n",
      "    \n",
      "    >>> np.reshape(a, (3,-1))       # the unspecified value is inferred to be 2\n",
      "    array([[1, 2],\n",
      "           [3, 4],\n",
      "           [5, 6]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1 = images.astype('float32')\n",
    "images1 = images / 255#进行归一化\n",
    "images1 = images.reshape(-1,50,50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(895, 50, 50, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[223.],\n",
       "        [224.],\n",
       "        [229.],\n",
       "        ...,\n",
       "        [218.],\n",
       "        [217.],\n",
       "        [216.]],\n",
       "\n",
       "       [[225.],\n",
       "        [234.],\n",
       "        [234.],\n",
       "        ...,\n",
       "        [221.],\n",
       "        [220.],\n",
       "        [218.]],\n",
       "\n",
       "       [[235.],\n",
       "        [234.],\n",
       "        [235.],\n",
       "        ...,\n",
       "        [223.],\n",
       "        [221.],\n",
       "        [219.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[233.],\n",
       "        [236.],\n",
       "        [238.],\n",
       "        ...,\n",
       "        [218.],\n",
       "        [206.],\n",
       "        [216.]],\n",
       "\n",
       "       [[232.],\n",
       "        [235.],\n",
       "        [238.],\n",
       "        ...,\n",
       "        [217.],\n",
       "        [196.],\n",
       "        [208.]],\n",
       "\n",
       "       [[236.],\n",
       "        [236.],\n",
       "        [240.],\n",
       "        ...,\n",
       "        [212.],\n",
       "        [192.],\n",
       "        [197.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 进行数据集的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分测试集和训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((716, 50, 50, 1), (179, 50, 50, 1), (716, 5), (179, 5))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,test_X,train_Y,test_Y = train_test_split(images1, Y_one_hot, test_size=0.2, random_state=13)\n",
    "train_X.shape,test_X.shape,train_Y.shape,test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((572, 50, 50, 1), (144, 50, 50, 1), (572, 5), (144, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X,valid_X,train_Y,valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=13)\n",
    "train_X.shape,valid_X.shape,train_Y.shape,valid_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras使用文档\n",
    "### https://keras.io/zh/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential模型\n",
    "Sequential模型字面上的翻译是顺序模型，给人的第一感觉是那种简单的线性模型，\n",
    "但实际上Sequential模型可以构建非常复杂的神经网络，\n",
    "包括全连接神经网络、卷积神经网络(CNN)、循环神经网络(RNN)、等等。\n",
    "这里的Sequential更准确的应该理解为堆叠，通过堆叠许多层，构建出深度神经网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#添加二维卷积层\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='linear',padding='valid',input_shape=(50,50,1)))\n",
    "#添加激活函数\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "#添加对于空间数据的最大池化\n",
    "model.add(MaxPooling2D((2, 2),padding='valid'))\n",
    "#解决过拟合策略\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='linear',padding='valid'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='linear',padding='valid'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='valid'))\n",
    "model.add(Dropout(0.4))\n",
    "#将输入展平。不影响批量大小\n",
    "model.add(Flatten())\n",
    "#全连接层\n",
    "model.add(Dense(128, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.1))           \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='linear'))\n",
    "\n",
    "model.add(LeakyReLU(alpha=0.1))           \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the model  from summay perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 32)        320       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 48, 48, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 11, 11, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 11, 11, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               262272    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 363,525\n",
      "Trainable params: 363,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "###用神经网络来进行学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(572, 50, 50, 1)\n",
      "(572, 5)\n",
      "(144, 50, 50, 1)\n",
      "(144, 5)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(valid_X.shape)\n",
    "print(valid_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建日志\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logdir = r\"D:\\python\\Face-detection-and-Emotion-recognition-system\\%s\" % stamp\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TensorBoard in module keras.callbacks:\n",
      "\n",
      "class TensorBoard(Callback, keras.utils.version_utils.TensorBoardVersionSelector)\n",
      " |  TensorBoard(*args, **kwargs)\n",
      " |  \n",
      " |  Enable visualizations for TensorBoard.\n",
      " |  \n",
      " |  TensorBoard is a visualization tool provided with TensorFlow.\n",
      " |  \n",
      " |  This callback logs events for TensorBoard, including:\n",
      " |  \n",
      " |  * Metrics summary plots\n",
      " |  * Training graph visualization\n",
      " |  * Weight histograms\n",
      " |  * Sampled profiling\n",
      " |  \n",
      " |  When used in `Model.evaluate`, in addition to epoch summaries, there will be\n",
      " |  a summary that records evaluation metrics vs `Model.optimizer.iterations`\n",
      " |  written. The metric names will be prepended with `evaluation`, with\n",
      " |  `Model.optimizer.iterations` being the step in the visualized TensorBoard.\n",
      " |  \n",
      " |  If you have installed TensorFlow with pip, you should be able\n",
      " |  to launch TensorBoard from the command line:\n",
      " |  \n",
      " |  ```\n",
      " |  tensorboard --logdir=path_to_your_logs\n",
      " |  ```\n",
      " |  \n",
      " |  You can find more information about TensorBoard\n",
      " |  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).\n",
      " |  \n",
      " |  Args:\n",
      " |      log_dir: the path of the directory where to save the log files to be\n",
      " |        parsed by TensorBoard. e.g. log_dir = os.path.join(working_dir,\n",
      " |        'logs') This directory should not be reused by any other callbacks.\n",
      " |      histogram_freq: frequency (in epochs) at which to compute\n",
      " |        weight histograms for the layers of the model. If set to 0, histograms\n",
      " |        won't be computed. Validation data (or split) must be specified for\n",
      " |        histogram visualizations.\n",
      " |      write_graph: whether to visualize the graph in TensorBoard. The log file\n",
      " |        can become quite large when write_graph is set to True.\n",
      " |      write_images: whether to write model weights to visualize as image in\n",
      " |        TensorBoard.\n",
      " |      write_steps_per_second: whether to log the training steps per second\n",
      " |        into Tensorboard. This supports both epoch and batch frequency\n",
      " |        logging.\n",
      " |      update_freq: **disabled**\n",
      " |  \n",
      " |        Warning: Batch-level summary writing using `update_freq` is\n",
      " |        currently unsupported. A suggested workaround is shown in the\n",
      " |        [TensorBoard Scalars tutorial](https://www.tensorflow.org/tensorboard/scalars_and_keras#batch-level_logging). # pylint: disable=protected-access\n",
      " |  \n",
      " |      profile_batch: Profile the batch(es) to sample compute characteristics.\n",
      " |        profile_batch must be a non-negative integer or a tuple of integers.\n",
      " |        A pair of positive integers signify a range of batches to profile.\n",
      " |        By default, profiling is disabled.\n",
      " |      embeddings_freq: frequency (in epochs) at which embedding layers will be\n",
      " |        visualized. If set to 0, embeddings won't be visualized.\n",
      " |      embeddings_metadata: Dictionary which maps embedding layer names to the\n",
      " |        filename of a file in which to save metadata for the embedding layer.\n",
      " |        In case the same metadata file is to be\n",
      " |        used for all embedding layers, a single filename can be passed.\n",
      " |  \n",
      " |  Examples:\n",
      " |  \n",
      " |  Basic usage:\n",
      " |  \n",
      " |  ```python\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  # Then run the tensorboard command to view the visualizations.\n",
      " |  ```\n",
      " |  \n",
      " |  \n",
      " |  Profiling:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Profile a single batch, e.g. the 5th batch.\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
      " |      log_dir='./logs', profile_batch=5)\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  \n",
      " |  # Profile a range of batches, e.g. from 10 to 20.\n",
      " |  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
      " |      log_dir='./logs', profile_batch=(10,20))\n",
      " |  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TensorBoard\n",
      " |      Callback\n",
      " |      keras.utils.version_utils.TensorBoardVersionSelector\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should\n",
      " |      only be called during TRAIN mode.\n",
      " |      \n",
      " |      Args:\n",
      " |          epoch: Integer, index of epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs=None)\n",
      " |      Runs metrics and histogram summaries at epoch end.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_test_batch_end()` is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently the output of the last call to\n",
      " |            `on_epoch_end()` is passed to this argument for this method but\n",
      " |            that may change in the future.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |      Sets Keras model and writes graph if specified.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Callback:\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Args:\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Currently no data is passed to this argument for this\n",
      " |            method but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Note that if the `steps_per_execution` argument to `compile` in\n",
      " |      `tf.keras.Model` is set to `N`, this method will only be called every\n",
      " |      `N` batches.\n",
      " |      \n",
      " |      Args:\n",
      " |          batch: Integer, index of batch within the current epoch.\n",
      " |          logs: Dict. Aggregated metric results up until this batch.\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from keras.utils.version_utils.TensorBoardVersionSelector:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwargs)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.callbacks.TensorBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 2s 166ms/step - loss: 1.6932 - accuracy: 0.2692 - val_loss: 1.6830 - val_accuracy: 0.2847\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 1.7281 - accuracy: 0.2657 - val_loss: 1.8826 - val_accuracy: 0.2639\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.6918 - accuracy: 0.2517 - val_loss: 2.2425 - val_accuracy: 0.2778\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 162ms/step - loss: 1.6336 - accuracy: 0.2972 - val_loss: 1.7572 - val_accuracy: 0.2708\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 1.6265 - accuracy: 0.2657 - val_loss: 1.6839 - val_accuracy: 0.3194\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1s 154ms/step - loss: 1.5986 - accuracy: 0.2867 - val_loss: 1.6654 - val_accuracy: 0.2778\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.5872 - accuracy: 0.3007 - val_loss: 1.7690 - val_accuracy: 0.3194\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 155ms/step - loss: 1.6163 - accuracy: 0.3024 - val_loss: 1.6258 - val_accuracy: 0.3194\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 159ms/step - loss: 1.5756 - accuracy: 0.2797 - val_loss: 1.6491 - val_accuracy: 0.3125\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.5435 - accuracy: 0.3024 - val_loss: 1.6862 - val_accuracy: 0.3056\n"
     ]
    }
   ],
   "source": [
    "model_train = model.fit(train_X, train_Y, \n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(valid_X, valid_Y),\n",
    "                        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9512), started 0:05:26 ago. (Use '!kill 9512' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cc78e19a75bcf1d7\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cc78e19a75bcf1d7\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = model.evaluate(test_X, test_Y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 进行模型评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model_train.history['accuracy']\n",
    "val_accuracy = model_train.history['val_accuracy']\n",
    "loss = model_train.history['loss']\n",
    "val_loss = model_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "#plot the loss and accuracy\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_types = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_types.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_types = np.argmax(np.round(predicted_types),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y = np.argmax(np.round(test_Y),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_types.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## view the correcr the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_types==test_Y)[0]\n",
    "\n",
    "print (\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[50:59]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct].reshape(50,50), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_types[correct], test_Y[correct]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_types!=test_Y)[0]\n",
    "print (\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[incorrect].reshape(50,50), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_types[incorrect], test_Y[incorrect]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 进行模型的评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\n",
    "print(classification_report(test_Y, predicted_types, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
